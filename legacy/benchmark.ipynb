{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09035df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Mounting onto Google Colab\n",
    "from google.colab import files \n",
    "files.download('examples.txt')\n",
    "\n",
    "from google.colab import drive \n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "## TODO use nn.functional where possible for speed as they are often faster than nn.Module counterparts\n",
    "## TODO implement squareplus activation for benchmarking\n",
    "\"\"\"\n",
    "Activation Functions\n",
    "\"\"\"\n",
    "def SquarePlus(x, beta=4):\n",
    "    \"\"\"Squareplus activation function.\"\"\"\n",
    "    return 0.5 * (x + torch.sqrt(x**2 + beta))\n",
    "\n",
    "def ReLU(x):\n",
    "    return F.relu(x)\n",
    "\n",
    "def SiLU(x):\n",
    "    return F.silu(x)\n",
    "\n",
    "def GELU(x):\n",
    "    return F.gelu(x)\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return F.sigmoid(x)\n",
    "\n",
    "def LeakyReLU(x, negative_slope=0.01):\n",
    "    return F.leaky_relu(x, negative_slope=negative_slope)\n",
    "\n",
    "def PReLU(x, weight=0.25):\n",
    "    return F.prelu(x, torch.tensor(weight, device=x.device, dtype=x.dtype))\n",
    "\n",
    "def ELU(x, alpha=1.0):\n",
    "    return F.elu(x, alpha=alpha)\n",
    "\n",
    "def Hardshrink(x, lambd=0.5):\n",
    "    return F.hardshrink(x, lambd=lambd)\n",
    "\n",
    "def Softshrink(x, lambd=0.5):\n",
    "    return F.softshrink(x, lambd=lambd)\n",
    "\n",
    "def Tanhshrink(x):\n",
    "    return F.tanhshrink(x)\n",
    "\n",
    "def Hardtanh(x, min_val=-1.0, max_val=1.0):\n",
    "    return F.hardtanh(x, min_val=min_val, max_val=max_val)\n",
    "\n",
    "def Softplus(x, beta=1, threshold=20):\n",
    "    return F.softplus(x, beta=beta, threshold=threshold)\n",
    "\n",
    "def Softsign(x):\n",
    "    return F.softsign(x)\n",
    "\n",
    "def Tanh(x):\n",
    "    return F.tanh(x)\n",
    "\n",
    "def CELU(x, alpha=1.0):\n",
    "    return F.celu(x, alpha=alpha)\n",
    "\n",
    "def Swish(x):\n",
    "    return F.silu(x)  # Swish is equivalent to SiLU\n",
    "\n",
    "def Mish(x):\n",
    "    return F.mish(x)\n",
    "\n",
    "def HardSwish(x):\n",
    "    return F.hardswish(x)\n",
    "\n",
    "def HardSigmoid(x):\n",
    "    return F.hardsigmoid(x)\n",
    "\n",
    "def ArcTan(x):\n",
    "    return 0.5 + (1.0 / torch.pi) * torch.arctan(x)\n",
    "\n",
    "def ArcTan_Approx(x):\n",
    "    return (0.5 + torch.clamp(x, min=0)) / (1.0 + torch.abs(x))\n",
    "\n",
    "def ZiLU(x):\n",
    "    return x * (0.5 + (1.0 / torch.pi) * torch.arctan(x))\n",
    "\n",
    "def ZiLU_Approx(x):\n",
    "    return x * ((0.5 + torch.clamp(x, min=0)) / (1.0 + torch.abs(x)))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Time benchmarking for various activation functions on different devices (forward and backward passes). \n",
    "\"\"\"\n",
    "# ...existing code...\n",
    "\n",
    "def benchmark_activation(activation_fn, input_tensor, device, num_warmup=10, num_iterations=100, compile=False):\n",
    "    \"\"\"\n",
    "    Benchmark forward and backward pass times for an activation function.\n",
    "    \"\"\"\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    if compile: \n",
    "        activation_fn = torch.compile(activation_fn)\n",
    "        \n",
    "    # Warmup\n",
    "    for _ in range(num_warmup):\n",
    "        test_input = input_tensor.clone().detach().requires_grad_(True)\n",
    "        output = activation_fn(test_input)\n",
    "        if test_input.requires_grad:\n",
    "            output.sum().backward()\n",
    "    \n",
    "    # Synchronize device\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    elif device == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    # Benchmark forward pass\n",
    "    forward_times = []\n",
    "    for _ in range(num_iterations):\n",
    "        test_input = input_tensor.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        elif device == 'mps':\n",
    "            torch.mps.synchronize()\n",
    "            \n",
    "        start = time.perf_counter()\n",
    "        output = activation_fn(test_input)\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        elif device == 'mps':\n",
    "            torch.mps.synchronize()\n",
    "        \n",
    "        end = time.perf_counter()\n",
    "        forward_times.append((end - start) * 1000)\n",
    "        \n",
    "        # Keep output alive to prevent optimization\n",
    "        del output\n",
    "    \n",
    "    # Benchmark backward pass\n",
    "    backward_times = []\n",
    "    for _ in range(num_iterations):\n",
    "        test_input = input_tensor.clone().detach().requires_grad_(True)\n",
    "        output = activation_fn(test_input)\n",
    "        loss = output.sum()\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        elif device == 'mps':\n",
    "            torch.mps.synchronize()\n",
    "            \n",
    "        start = time.perf_counter()\n",
    "        loss.backward()\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        elif device == 'mps':\n",
    "            torch.mps.synchronize()\n",
    "        \n",
    "        end = time.perf_counter()\n",
    "        backward_times.append((end - start) * 1000)\n",
    "    \n",
    "    return {\n",
    "        'forward_mean': sum(forward_times) / len(forward_times),\n",
    "        'forward_std': torch.tensor(forward_times).std().item(),\n",
    "        'backward_mean': sum(backward_times) / len(backward_times),\n",
    "        'backward_std': torch.tensor(backward_times).std().item()\n",
    "    }\n",
    "    \n",
    "def run_benchmarks():\n",
    "    \"\"\"Run benchmarks for all activation functions on all available devices.\"\"\"\n",
    "    \n",
    "    # Test configuration\n",
    "    input_size = 1000000  # 1 million elements\n",
    "    \n",
    "    # Create test input\n",
    "    input_tensor = torch.randn(input_size, requires_grad=True)\n",
    "    \n",
    "    # Activation functions to test\n",
    "    activations = {\n",
    "        \"ReLU\": ReLU,\n",
    "        \"SiLU\": SiLU,\n",
    "        \"GELU\": GELU,\n",
    "        \"Sigmoid\": Sigmoid,\n",
    "        \"LeakyReLU\": LeakyReLU,\n",
    "        \"PReLU\": PReLU,\n",
    "        \"ELU\": ELU,\n",
    "        \"Hardshrink\": Hardshrink,\n",
    "        \"Softshrink\": Softshrink,\n",
    "        \"Tanhshrink\": Tanhshrink,\n",
    "        \"Hardtanh\": Hardtanh,\n",
    "        \"Softplus\": Softplus,\n",
    "        \"Softsign\": Softsign,\n",
    "        \"Tanh\": Tanh,\n",
    "        \"CELU\": CELU,\n",
    "        \"Swish\": Swish,\n",
    "        \"Mish\": Mish,\n",
    "        \"HardSwish\": HardSwish,\n",
    "        \"HardSigmoid\": HardSigmoid,\n",
    "        \"ArcTan\": ArcTan,\n",
    "        \"ArcTan_Approx\": ArcTan_Approx,\n",
    "        \"ZiLU\": ZiLU,\n",
    "        \"ZiLU_Approx\": ZiLU_Approx\n",
    "    }\n",
    "    \n",
    "    # Determine available devices\n",
    "    devices = ['cpu']\n",
    "    if torch.cuda.is_available():\n",
    "        devices.append('cuda')\n",
    "    if torch.backends.mps.is_available():\n",
    "        devices.append('mps')\n",
    "    \n",
    "    print(f\"Available devices: {devices}\")\n",
    "    print(f\"Input shape: {input_tensor.shape}\\n\")\n",
    "    \n",
    "    # Run benchmarks\n",
    "    results = {}\n",
    "    for device in devices:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Device: {device.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results[device] = {}\n",
    "        \n",
    "        for name, activation_fn in activations.items():\n",
    "            print(f\"\\nBenchmarking {name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Create fresh input for each test\n",
    "                test_input = input_tensor.clone().detach().requires_grad_(True)\n",
    "                \n",
    "                # Run benchmark\n",
    "                timing = benchmark_activation(\n",
    "                    activation_fn, \n",
    "                    test_input, \n",
    "                    device,\n",
    "                    num_warmup=10,\n",
    "                    num_iterations=100\n",
    "                )\n",
    "                \n",
    "                results[device][name] = timing\n",
    "                \n",
    "                print(f\"  Forward:  {timing['forward_mean']:.4f} ± {timing['forward_std']:.4f} ms\")\n",
    "                print(f\"  Backward: {timing['backward_mean']:.4f} ± {timing['backward_std']:.4f} ms\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error: {e}\")\n",
    "                results[device][name] = None\n",
    "    \n",
    "    # Print summary table\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for device in devices:\n",
    "        print(f\"\\n{device.upper()}:\")\n",
    "        print(f\"{'Activation':<20} {'Forward (ms)':<20} {'Backward (ms)':<20}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for name in activations.keys():\n",
    "            if results[device].get(name):\n",
    "                timing = results[device][name]\n",
    "                fwd = f\"{timing['forward_mean']:.4f} ± {timing['forward_std']:.4f}\"\n",
    "                bwd = f\"{timing['backward_mean']:.4f} ± {timing['backward_std']:.4f}\"\n",
    "                print(f\"{name:<20} {fwd:<20} {bwd:<20}\")\n",
    "            else:\n",
    "                print(f\"{name:<20} {'N/A':<20} {'N/A':<20}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def results_to_dataframe(results):\n",
    "    \"\"\"\n",
    "    Convert benchmark results to a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        results: Nested dict with structure {device: {activation: {metric: value}}}\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with columns: Device, Activation, Forward_Mean, Forward_Std, Backward_Mean, Backward_Std\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for device, activations in results.items():\n",
    "        for activation_name, timing in activations.items():\n",
    "            if timing is not None:\n",
    "                data.append({\n",
    "                    'Device': device,\n",
    "                    'Activation': activation_name,\n",
    "                    'Forward_Mean (ms)': timing['forward_mean'],\n",
    "                    'Forward_Std (ms)': timing['forward_std'],\n",
    "                    'Backward_Mean (ms)': timing['backward_mean'],\n",
    "                    'Backward_Std (ms)': timing['backward_std']\n",
    "                })\n",
    "            else:\n",
    "                data.append({\n",
    "                    'Device': device,\n",
    "                    'Activation': activation_name,\n",
    "                    'Forward_Mean (ms)': None,\n",
    "                    'Forward_Std (ms)': None,\n",
    "                    'Backward_Mean (ms)': None,\n",
    "                    'Backward_Std (ms)': None\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_benchmarks()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = results_to_dataframe(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = './benchmark_results.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b86d84",
   "metadata": {},
   "source": [
    "## GPU Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeb94379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f550e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA A100-SXM4-40GB\n",
      "Total memory: 42.47 GB\n",
      "Allocated memory: 0.00 GB\n",
      "Cached memory: 0.05 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "\n",
    "# Get number of GPUs\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Get current GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Get memory info (in bytes)\n",
    "    print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36f0ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-SXM4-40GB, 40960, 39962, 543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free,memory.used', \n",
    "                        '--format=csv,noheader,nounits'], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebedc769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-40GB\n",
      "  Total memory: 42.95 GB\n",
      "  Free memory: 41.90 GB\n",
      "  Used memory: 1.05 GB\n"
     ]
    }
   ],
   "source": [
    "import pynvml\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "device_count = pynvml.nvmlDeviceGetCount()\n",
    "\n",
    "for i in range(device_count):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    \n",
    "    print(f\"GPU {i}: {pynvml.nvmlDeviceGetName(handle)}\")\n",
    "    print(f\"  Total memory: {info.total / 1e9:.2f} GB\")\n",
    "    print(f\"  Free memory: {info.free / 1e9:.2f} GB\")\n",
    "    print(f\"  Used memory: {info.used / 1e9:.2f} GB\")\n",
    "\n",
    "pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efac07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmpcdghsf86', '/usr/local/lib/python3.12/dist-packages/setuptools/_vendor']\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os \n",
    "print(sys.path) \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a65b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
